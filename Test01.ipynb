{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit88dab3afd0484f4384f3bf9941a06ded",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importan las librerias con las cuales se va a desarrollar el ejercicio\n",
    "\n",
    "#Manejo de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob \n",
    "import openpyxl\n",
    "\n",
    "#Gráficos\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from xverse.transformer import WOE\n",
    "from xverse.transformer import MonotonicBinning\n",
    "from xverse.ensemble import VotingSelector\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(5561, 1760)\n(8322, 1761)\n"
    }
   ],
   "source": [
    "# Lee los nombres de archivos del directorio de trabajo\n",
    "filenames = glob.glob('Datos/*.csv')\n",
    "df = pd.DataFrame()\n",
    "for filename in filenames:\n",
    "    data = pd.read_csv(filename)\n",
    "    print(data.shape)\n",
    "    df = df.append(data)\n",
    "    df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>AA</th>\n      <th>AC</th>\n      <th>AD</th>\n      <th>AE</th>\n      <th>AF</th>\n      <th>AG</th>\n      <th>AH</th>\n      <th>AI</th>\n      <th>AK</th>\n      <th>...</th>\n      <th>tausw28</th>\n      <th>tausw29</th>\n      <th>tausw3</th>\n      <th>tausw30</th>\n      <th>tausw4</th>\n      <th>tausw5</th>\n      <th>tausw6</th>\n      <th>tausw7</th>\n      <th>tausw8</th>\n      <th>tausw9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>28.571</td>\n      <td>16.67</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.979</td>\n      <td>0.0</td>\n      <td>1.895</td>\n      <td>0.994</td>\n      <td>0.781</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.769</td>\n      <td>0.0</td>\n      <td>2.119</td>\n      <td>0.028</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.844</td>\n      <td>0.0</td>\n      <td>0.977</td>\n      <td>0.096</td>\n      <td>0.138</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.564</td>\n      <td>0.0</td>\n      <td>0.504</td>\n      <td>0.096</td>\n      <td>0.095</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.813</td>\n      <td>0.0</td>\n      <td>0.980</td>\n      <td>0.848</td>\n      <td>0.065</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1761 columns</p>\n</div>",
      "text/plain": "        A     AA   AC   AD   AE   AF   AG   AH   AI   AK  ...  tausw28  \\\n0  28.571  16.67  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n1   0.000   0.00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n2   0.000   0.00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n3   0.000   0.00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n4   0.000   0.00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n\n   tausw29  tausw3  tausw30  tausw4  tausw5  tausw6  tausw7  tausw8  tausw9  \n0      0.0   1.979      0.0   1.895   0.994   0.781     0.0     0.0     0.0  \n1      0.0   1.769      0.0   2.119   0.028   1.000     0.0     0.0     0.0  \n2      0.0   1.844      0.0   0.977   0.096   0.138     0.0     0.0     0.0  \n3      0.0   0.564      0.0   0.504   0.096   0.095     0.0     0.0     0.0  \n4      0.0   1.813      0.0   0.980   0.848   0.065     0.0     0.0     0.0  \n\n[5 rows x 1761 columns]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la columna que ennumera del primer archivo\n",
    "df_dep = df.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num</th>\n      <th>A</th>\n      <th>AA</th>\n      <th>AC</th>\n      <th>AD</th>\n      <th>AE</th>\n      <th>AF</th>\n      <th>AG</th>\n      <th>AH</th>\n      <th>AI</th>\n      <th>...</th>\n      <th>tausw28</th>\n      <th>tausw29</th>\n      <th>tausw3</th>\n      <th>tausw30</th>\n      <th>tausw4</th>\n      <th>tausw5</th>\n      <th>tausw6</th>\n      <th>tausw7</th>\n      <th>tausw8</th>\n      <th>tausw9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>28.571</td>\n      <td>16.67</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.979</td>\n      <td>0.0</td>\n      <td>1.895</td>\n      <td>0.994</td>\n      <td>0.781</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.769</td>\n      <td>0.0</td>\n      <td>2.119</td>\n      <td>0.028</td>\n      <td>1.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>0.000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.844</td>\n      <td>0.0</td>\n      <td>0.977</td>\n      <td>0.096</td>\n      <td>0.138</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3</td>\n      <td>0.000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.564</td>\n      <td>0.0</td>\n      <td>0.504</td>\n      <td>0.096</td>\n      <td>0.095</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4</td>\n      <td>0.000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.813</td>\n      <td>0.0</td>\n      <td>0.980</td>\n      <td>0.848</td>\n      <td>0.065</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1760 columns</p>\n</div>",
      "text/plain": "   num       A     AA   AC   AD   AE   AF   AG   AH   AI  ...  tausw28  \\\n0    0  28.571  16.67  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n1    1   0.000   0.00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n2    2   0.000   0.00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n3    3   0.000   0.00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n4    4   0.000   0.00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n\n   tausw29  tausw3  tausw30  tausw4  tausw5  tausw6  tausw7  tausw8  tausw9  \n0      0.0   1.979      0.0   1.895   0.994   0.781     0.0     0.0     0.0  \n1      0.0   1.769      0.0   2.119   0.028   1.000     0.0     0.0     0.0  \n2      0.0   1.844      0.0   0.977   0.096   0.138     0.0     0.0     0.0  \n3      0.0   0.564      0.0   0.504   0.096   0.095     0.0     0.0     0.0  \n4      0.0   1.813      0.0   0.980   0.848   0.065     0.0     0.0     0.0  \n\n[5 rows x 1760 columns]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos una columna enumerando cada fila\n",
    "df_dep = df_dep.assign(num=[0 + i for i in range(len(df_dep))])[['num'] + df_dep.columns.tolist()]\n",
    "# Guardamos las variables num y sequence\n",
    "df_1 = df_dep[[\"num\", \"sequence\"]]\n",
    "# Eliminamos la variable sequence del dataframe depurado\n",
    "df_dep.pop(\"sequence\")\n",
    "df_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos la variable objetivo\n",
    "y = df_dep.pop(\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos el set de datos\n",
    "names = df_dep.columns\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df_dep)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particionamos el set de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, y, test_size = .2, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se balancean los datos de entrenamiento\n",
    "sm = SMOTE(random_state=42)\n",
    "sm_data_X,sm_data_y=sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.series.Series"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convirtiendo en DataFrame\n",
    "bal_data_X = pd.DataFrame(sm_data_X, columns=X_train.columns)\n",
    "type(bal_data_X)\n",
    "bal_data_y = pd.Series(sm_data_y)\n",
    "type(bal_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x23fba47c6c8>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos las clases\n",
    "sns.countplot(bal_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "VotingSelector(exclude_features=None, feature_names='all',\n               handle_category='woe', minimum_votes=0, no_of_features=879,\n               numerical_missing_values='median',\n               selection_techniques=['WOE', 'RF', 'RFE', 'ETC', 'CS', 'L_ONE'])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionamos las variables mas importantes a partir de votos de modelos\n",
    "vs = VotingSelector()\n",
    "vs.fit(bal_data_X, bal_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Estas son las variables más importantes, según el consenso de votos de selección, 5  donde las columnas de interes son: ['M' '_PolarizabilityT12' 'GearyAuto_FreeEnergy5' 'Y' 'MR'\n '_PolarizabilityD2001' 'embed_0_50' 'embed_1_41' 'embed_0_29'\n 'GearyAuto_FreeEnergy16' 'embed_0_40' 'QSOSW16' 'GearyAuto_FreeEnergy15'\n 'MoreauBrotoAuto_Mutability10' 'embed_0_94' '_ChargeD1025' 'N'\n 'GearyAuto_ResidueASA1' 'GearyAuto_FreeEnergy2'\n 'MoranAuto_Hydrophobicity11' 'embed_2_25' 'QSOSW21' 'embed_2_82'\n 'embed_0_49' 'embed_2_91' 'QSOgrant24' 'QSOSW24' 'embed_2_22'\n '_PolarizabilityD3050' '_NormalizedVDWVD2050' 'GearyAuto_ResidueASA2'\n 'embed_2_42' '_SolventAccessibilityD1050' 'embed_2_94'\n '_HydrophobicityC1' '_NormalizedVDWVD1100' 'C' 'embed_1_49' 'QSOSW3'\n 'QSOgrant3' 'QSOgrant19' 'QSOSW19' '_HydrophobicityD3025'\n '_PolarizabilityC1' 'R' '_PolarizabilityD1100' 'embed_2_65'\n '_PolarityD2025' 'embed_2_41' 'embed_0_42' '_SecondaryStrD2025'\n 'embed_2_57' 'embed_1_57' 'MK' 'embed_2_24' 'tausw4' 'taugrant4'\n 'MoreauBrotoAuto_Mutability5' 'GearyAuto_AvFlexibility10' 'Q' 'CK'\n '_SolventAccessibilityD3050' '_NormalizedVDWVD2025' '_SecondaryStrD2050'\n '_PolarizabilityD1075' 'GearyAuto_Steric3' 'GearyAuto_Steric8'\n 'embed_2_4' 'embed_2_53' 'GearyAuto_ResidueASA12' 'embed_2_40'\n 'GearyAuto_ResidueASA23' 'GearyAuto_Steric6' 'embed_1_50' 'embed_0_68'\n '_HydrophobicityD2050' '_HydrophobicityT12' '_PolarityD3001' 'embed_1_22'\n 'embed_0_53' 'embed_2_47' 'embed_0_7' 'tausw7' 'taugrant7' 'embed_2_75'\n 'embed_1_90' 'GearyAuto_Steric22' 'embed_1_77' 'GearyAuto_FreeEnergy23'\n 'embed_2_77' 'embed_0_4' 'embed_2_62' '_HydrophobicityT23'\n 'GearyAuto_FreeEnergy25' 'embed_2_50' 'QSOgrant34'\n 'MoreauBrotoAuto_Mutability6' 'QSOgrant25' 'QSOSW25' 'embed_2_93'\n 'embed_2_90' 'GearyAuto_ResidueVol1' '_ChargeD1100' 'embed_2_28'\n '_SecondaryStrC1' 'GearyAuto_Mutability22' 'embed_2_8'\n '_SecondaryStrD1050' 'embed_1_87' '_HydrophobicityT13'\n '_PolarizabilityD1050' 'molecular_weight' '_PolarityD3075' 'embed_0_96'\n 'embed_0_34' 'embed_1_75' 'MoreauBrotoAuto_Mutability7' 'embed_2_21'\n 'embed_1_96' '_PolarityD2001' 'GearyAuto_Hydrophobicity8' '_ChargeT12'\n 'QSOgrant22' '_SecondaryStrD2001' 'embed_2_20' '_SecondaryStrD3100'\n '_SolventAccessibilityC1' 'QSOSW27' 'GearyAuto_AvFlexibility2'\n 'QSOgrant27' 'embed_0_37' 'GearyAuto_AvFlexibility11' 'isoelectric_point'\n 'QSOSW22' '_SolventAccessibilityD3025' 'embed_1_24'\n 'GearyAuto_Mutability14' 'GearyAuto_Mutability9' 'GearyAuto_Mutability3'\n 'KK' '_SolventAccessibilityD3100' '_ChargeD2001' 'GearyAuto_ResidueASA5'\n '_SolventAccessibilityT13' '_PolarizabilityD2050' '_PolarityD2075' 'W'\n 'QSOgrant4' '_ChargeT23' 'MoreauBrotoAuto_Mutability1' 'QSOSW4'\n '_NormalizedVDWVD3025' '_PolarizabilityD3025' 'GearyAuto_Mutability13'\n '_SecondaryStrD1025' '_ChargeC3' '_HydrophobicityD3075' 'QSOgrant18'\n 'QSOSW18' 'GearyAuto_Mutability5' 'D' '_NormalizedVDWVD2075' 'QSOgrant13'\n '_SolventAccessibilityD1025' '_SolventAccessibilityC3' '_PolarityD2100'\n 'GearyAuto_Hydrophobicity7' 'GearyAuto_Mutability7' 'K' 'charge_density'\n 'GearyAuto_Hydrophobicity4' '_ChargeC1' 'MoranAuto_Hydrophobicity2'\n '_HydrophobicityD3001' '_ChargeD3100' 'GearyAuto_FreeEnergy3'\n 'GearyAuto_Polarizability10' 'embed_0_51' '_SolventAccessibilityD1001'\n '_SolventAccessibilityD3001' '_SecondaryStrD1001' '_NormalizedVDWVT12'\n '_SecondaryStrD3050' '_NormalizedVDWVC2' 'GearyAuto_FreeEnergy12'\n '_PolarizabilityD3001' '_NormalizedVDWVD3001' '_PolarityD1001' 'E'\n 'GearyAuto_AvFlexibility14' 'GearyAuto_Mutability6'\n 'GearyAuto_FreeEnergy8' '_PolarityC3' '_ChargeD3050' 'embed_0_59'\n 'QSOSW13' 'GearyAuto_Mutability10' 'GearyAuto_Mutability1' 'embed_1_65'\n 'embed_2_29' 'GearyAuto_ResidueVol3' 'tausw10'\n 'MoreauBrotoAuto_ResidueASA2' 'embed_0_1' 'GearyAuto_Steric20'\n 'MoranAuto_ResidueASA1' 'QSOgrant30' 'embed_2_19' 'embed_0_79'\n 'MoranAuto_FreeEnergy8' 'GearyAuto_AvFlexibility17' 'embed_1_68'\n 'GearyAuto_FreeEnergy17' 'GearyAuto_Mutability26' '_PolarizabilityD3075'\n 'embed_1_29' 'tausw8' 'embed_2_44' '_NormalizedVDWVD3075'\n '_PolarityD1025' 'embed_2_87' '_HydrophobicityC3' '_NormalizedVDWVT13'\n '_PolarizabilityD2025' 'MoreauBrotoAuto_ResidueVol2' 'tausw11'\n 'embed_0_85' 'embed_0_0' 'length' 'embed_1_40' 'MoranAuto_Mutability7'\n 'GearyAuto_ResidueVol5' 'GearyAuto_FreeEnergy18' 'embed_1_23'\n 'embed_0_58' 'GearyAuto_Steric5' 'KC' 'GearyAuto_AvFlexibility3'\n 'MoranAuto_Mutability13' 'GearyAuto_Polarizability11' 'tausw15'\n 'taugrant15' 'GearyAuto_Mutability23' 'embed_0_41'\n 'MoreauBrotoAuto_Mutability8' 'embed_0_22' 'taugrant12' 'QSOSW32'\n 'MoreauBrotoAuto_AvFlexibility4' 'QSOgrant32' 'GearyAuto_Hydrophobicity2'\n 'GearyAuto_ResidueVol7' '_PolarityD3100' 'taugrant10'\n 'GearyAuto_AvFlexibility9' 'embed_0_23' 'embed_1_8'\n 'GearyAuto_Hydrophobicity5' 'MoreauBrotoAuto_ResidueASA9'\n 'GearyAuto_FreeEnergy26' 'embed_1_44' 'GearyAuto_ResidueASA6'\n 'MoranAuto_AvFlexibility9' 'MoranAuto_Steric10' 'QSOgrant15' 'QSOSW15'\n 'embed_0_24' 'GearyAuto_ResidueVol4' 'L' 'QSOSW5' 'QSOgrant5'\n 'embed_2_26' 'embed_2_11' 'embed_2_37' 'embed_1_73'\n 'GearyAuto_ResidueASA4' '_HydrophobicityD1001'\n '_SolventAccessibilityD2001' 'embed_1_34' 'embed_1_7'\n 'MoreauBrotoAuto_AvFlexibility10' 'embed_1_26'\n 'MoreauBrotoAuto_Hydrophobicity8' 'embed_0_21' '_SecondaryStrT12'\n 'embed_1_64' 'MoranAuto_ResidueVol2' 'PR' 'taugrant8'\n 'GearyAuto_ResidueASA3' '_SolventAccessibilityC2' 'embed_1_18'\n 'MoranAuto_FreeEnergy6' 'MoranAuto_FreeEnergy5' 'embed_0_93'\n 'MoranAuto_Steric9' 'MoreauBrotoAuto_Mutability11'\n 'MoreauBrotoAuto_FreeEnergy10' 'G' 'embed_2_39' 'MoranAuto_Steric1'\n 'MoreauBrotoAuto_Polarizability2' 'embed_2_7' 'QSOgrant11' 'QSOSW11'\n 'embed_0_65' '_NormalizedVDWVD2100' 'MoranAuto_Hydrophobicity8'\n 'MoranAuto_FreeEnergy1' 'embed_2_34' 'embed_2_38'\n 'GearyAuto_Hydrophobicity17' 'GearyAuto_Polarizability7'\n 'MoreauBrotoAuto_ResidueVol11' 'embed_0_39' 'GearyAuto_FreeEnergy24'\n 'GearyAuto_Steric4' 'embed_2_32' 'QSOgrant29' 'QSOSW29' 'embed_2_48'\n 'embed_2_27' 'GearyAuto_AvFlexibility1' 'embed_1_93'\n 'MoranAuto_AvFlexibility5' 'MoranAuto_FreeEnergy4' 'embed_0_15'\n 'embed_1_38' 'embed_0_91' 'MoreauBrotoAuto_Hydrophobicity9'\n 'GearyAuto_Polarizability2' 'embed_1_1' 'MoranAuto_Steric2'\n 'GearyAuto_Polarizability1' '_HydrophobicityD1025' 'QSOgrant21'\n 'MoreauBrotoAuto_ResidueVol12' 'GearyAuto_ResidueASA8'\n '_SecondaryStrD2100' 'embed_0_27' 'embed_1_39' '_PolarityT23'\n 'GearyAuto_Polarizability6' 'embed_1_91' 'embed_1_71' 'embed_0_86'\n 'MoreauBrotoAuto_ResidueVol10' 'embed_1_19' 'MoreauBrotoAuto_Mutability9'\n 'embed_1_36' 'embed_2_85' 'MoreauBrotoAuto_Hydrophobicity16'\n 'MoreauBrotoAuto_ResidueASA4' 'MoreauBrotoAuto_Hydrophobicity11'\n '_SecondaryStrD1075' 'MoranAuto_Hydrophobicity6'\n '_SolventAccessibilityD2025' 'GearyAuto_Hydrophobicity10' 'num' 'charge'\n '_NormalizedVDWVD1075' 'GearyAuto_FreeEnergy14' 'MN' 'MS'\n '_SecondaryStrD3075' 'MoranAuto_Mutability2' 'GearyAuto_ResidueVol9'\n '_NormalizedVDWVD1025' 'embed_0_25' 'GearyAuto_ResidueVol10' 'embed_1_51'\n 'embed_1_62' 'GearyAuto_FreeEnergy6' 'GearyAuto_FreeEnergy1'\n 'MoreauBrotoAuto_Mutability4' 'KI' '_ChargeT13' 'H'\n 'GearyAuto_Hydrophobicity14' 'embed_2_51' 'QSOSW31' 'QSOgrant31'\n '_HydrophobicityC2' '_NormalizedVDWVC1' 'GearyAuto_Hydrophobicity15'\n 'embed_0_57' 'KW' 'embed_2_59' 'MoranAuto_AvFlexibility13' 'embed_0_62'\n 'QSOgrant16' '_NormalizedVDWVD3050' 'MoranAuto_AvFlexibility2'\n '_ChargeD1050' 'aliphatic_index' 'embed_0_17' 'LL' 'QSOSW34'\n '_NormalizedVDWVD2001' 'embed_0_66' 'MV' 'GearyAuto_Steric10' 'RR'\n 'embed_0_84' 'GearyAuto_Steric11' 'MoranAuto_AvFlexibility7' 'MY'\n 'embed_2_0' 'MoranAuto_FreeEnergy14' 'MoreauBrotoAuto_Hydrophobicity13'\n 'embed_1_59' 'GK' 'MP' 'MI' 'GearyAuto_Hydrophobicity13' '_PolarityD3025'\n 'GearyAuto_Steric9' 'MoranAuto_AvFlexibility4' 'QSOSW7' 'QSOgrant7'\n '_PolarizabilityC3' '_SolventAccessibilityT12' 'GearyAuto_ResidueVol14'\n 'GearyAuto_Steric13' 'GearyAuto_FreeEnergy7' 'GearyAuto_FreeEnergy10'\n '_ChargeD3025' 'GearyAuto_Steric14' '_SecondaryStrD3025'\n 'GearyAuto_Hydrophobicity11' 'GearyAuto_FreeEnergy9' '_SecondaryStrC3'\n 'GearyAuto_AvFlexibility7' 'GearyAuto_Mutability12' '_ChargeD3001'\n 'GearyAuto_Mutability8' 'QSOSW6' 'QSOgrant6' 'GearyAuto_Mutability2'\n '_ChargeD3075' '_HydrophobicityD2001' '_NormalizedVDWVD1001'\n '_PolarityT13' 'QSOgrant12' 'QSOSW12' '_PolarityC2' '_SecondaryStrD3001'\n '_PolarizabilityD1001' 'ML' '_PolarityT12' '_NormalizedVDWVC3'\n 'GearyAuto_AvFlexibility12' 'GearyAuto_ResidueVol11' '_SecondaryStrT13'\n '_PolarizabilityD1025' 'embed_2_49' 'GearyAuto_Mutability11'\n 'GearyAuto_AvFlexibility8' 'embed_2_66' 'T' 'GearyAuto_AvFlexibility4'\n 'MoreauBrotoAuto_Mutability3' '_PolarityD2050' 'GearyAuto_Steric12'\n 'MoranAuto_Hydrophobicity7' 'QSOgrant17' '_SecondaryStrT23'\n 'GearyAuto_ResidueVol12' 'GearyAuto_FreeEnergy4' 'embed_1_66'\n 'MoranAuto_Hydrophobicity4' '_ChargeC2' 'MoreauBrotoAuto_Mutability2'\n 'MT' 'KL' 'LK' 'GearyAuto_Mutability4' 'QSOSW17' 'FL'\n '_SolventAccessibilityT23' 'embed_0_90' 'embed_1_0'\n 'GearyAuto_ResidueVol21' 'QSOgrant28' 'GearyAuto_ResidueVol6'\n 'GearyAuto_Steric1' 'embed_0_75' 'MoranAuto_FreeEnergy12' 'embed_2_23'\n 'KA' '_HydrophobicityD2025' 'QSOSW28' 'embed_2_17'\n 'GearyAuto_ResidueASA11' 'S' 'GearyAuto_ResidueVol2'\n 'MoranAuto_FreeEnergy10' '_ChargeD1075' 'GearyAuto_Hydrophobicity3'\n 'embed_1_4' '_NormalizedVDWVD1050' '_ChargeD1001'\n 'MoranAuto_AvFlexibility11' 'embed_1_46' 'embed_1_25' 'tausw13'\n '_HydrophobicityD2075' 'embed_1_17' '_PolarityD3050'\n 'GearyAuto_ResidueVol8' '_SolventAccessibilityD3075' 'GearyAuto_Steric2'\n 'embed_2_96']\n"
    }
   ],
   "source": [
    "delta_crit = 4\n",
    "priorizadas = vs.feature_votes_[vs.feature_votes_[\"Votes\"]>delta_crit][\"Variable_Name\"].values\n",
    "print(\"Estas son las variables más importantes, según el consenso de votos de selección,\", \\\n",
    "      delta_crit+1,\" donde las columnas de interes son:\",\\\n",
    "      priorizadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar con las caracteristicas seleccionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(513,)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priorizadas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num</th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>length</th>\n      <th>molecular_weight</th>\n      <th>charge</th>\n      <th>charge_density</th>\n      <th>isoelectric_point</th>\n      <th>gravy</th>\n      <th>instability_index</th>\n      <th>...</th>\n      <th>embed_2_90</th>\n      <th>embed_2_91</th>\n      <th>embed_2_92</th>\n      <th>embed_2_93</th>\n      <th>embed_2_94</th>\n      <th>embed_2_95</th>\n      <th>embed_2_96</th>\n      <th>embed_2_97</th>\n      <th>embed_2_98</th>\n      <th>embed_2_99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>33</td>\n      <td>3897.77</td>\n      <td>8.691</td>\n      <td>0.002230</td>\n      <td>11.404358</td>\n      <td>-0.112121</td>\n      <td>84.766667</td>\n      <td>...</td>\n      <td>-0.928374</td>\n      <td>2.771416</td>\n      <td>-0.851930</td>\n      <td>-0.459909</td>\n      <td>0.909622</td>\n      <td>1.402783</td>\n      <td>-3.848056</td>\n      <td>-0.528822</td>\n      <td>-0.740751</td>\n      <td>-0.257650</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1501</td>\n      <td>1</td>\n      <td>1</td>\n      <td>34</td>\n      <td>4003.64</td>\n      <td>7.590</td>\n      <td>0.001896</td>\n      <td>10.196106</td>\n      <td>-0.638235</td>\n      <td>76.035294</td>\n      <td>...</td>\n      <td>-1.030314</td>\n      <td>2.356963</td>\n      <td>-0.590644</td>\n      <td>-0.433246</td>\n      <td>0.362768</td>\n      <td>1.204798</td>\n      <td>-3.838024</td>\n      <td>-0.859893</td>\n      <td>-1.086264</td>\n      <td>0.052278</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1502</td>\n      <td>2</td>\n      <td>2</td>\n      <td>35</td>\n      <td>4121.92</td>\n      <td>6.689</td>\n      <td>0.001623</td>\n      <td>9.611023</td>\n      <td>-0.551429</td>\n      <td>16.851429</td>\n      <td>...</td>\n      <td>-0.846578</td>\n      <td>2.762231</td>\n      <td>-1.182640</td>\n      <td>-0.908285</td>\n      <td>0.802487</td>\n      <td>1.546229</td>\n      <td>-4.543212</td>\n      <td>-0.786475</td>\n      <td>-0.477468</td>\n      <td>-0.178319</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1503</td>\n      <td>3</td>\n      <td>3</td>\n      <td>31</td>\n      <td>3838.56</td>\n      <td>6.589</td>\n      <td>0.001717</td>\n      <td>9.802917</td>\n      <td>-0.200000</td>\n      <td>53.977419</td>\n      <td>...</td>\n      <td>-0.960986</td>\n      <td>1.742604</td>\n      <td>-0.981736</td>\n      <td>-0.098695</td>\n      <td>0.614634</td>\n      <td>0.774174</td>\n      <td>-2.818301</td>\n      <td>-0.395545</td>\n      <td>-0.738405</td>\n      <td>0.369630</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1504</td>\n      <td>4</td>\n      <td>4</td>\n      <td>33</td>\n      <td>3715.45</td>\n      <td>3.591</td>\n      <td>0.000967</td>\n      <td>8.981384</td>\n      <td>0.660606</td>\n      <td>62.042424</td>\n      <td>...</td>\n      <td>-1.034936</td>\n      <td>1.734715</td>\n      <td>-0.830263</td>\n      <td>-0.386610</td>\n      <td>0.836167</td>\n      <td>0.859871</td>\n      <td>-3.665342</td>\n      <td>-0.922017</td>\n      <td>-0.364447</td>\n      <td>-0.055827</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1761 columns</p>\n</div>",
      "text/plain": "    num  Unnamed: 0  Unnamed: 0.1  length  molecular_weight  charge  \\\n0  1500           0             0      33           3897.77   8.691   \n1  1501           1             1      34           4003.64   7.590   \n2  1502           2             2      35           4121.92   6.689   \n3  1503           3             3      31           3838.56   6.589   \n4  1504           4             4      33           3715.45   3.591   \n\n   charge_density  isoelectric_point     gravy  instability_index  ...  \\\n0        0.002230          11.404358 -0.112121          84.766667  ...   \n1        0.001896          10.196106 -0.638235          76.035294  ...   \n2        0.001623           9.611023 -0.551429          16.851429  ...   \n3        0.001717           9.802917 -0.200000          53.977419  ...   \n4        0.000967           8.981384  0.660606          62.042424  ...   \n\n   embed_2_90  embed_2_91  embed_2_92  embed_2_93  embed_2_94  embed_2_95  \\\n0   -0.928374    2.771416   -0.851930   -0.459909    0.909622    1.402783   \n1   -1.030314    2.356963   -0.590644   -0.433246    0.362768    1.204798   \n2   -0.846578    2.762231   -1.182640   -0.908285    0.802487    1.546229   \n3   -0.960986    1.742604   -0.981736   -0.098695    0.614634    0.774174   \n4   -1.034936    1.734715   -0.830263   -0.386610    0.836167    0.859871   \n\n   embed_2_96  embed_2_97  embed_2_98  embed_2_99  \n0   -3.848056   -0.528822   -0.740751   -0.257650  \n1   -3.838024   -0.859893   -1.086264    0.052278  \n2   -4.543212   -0.786475   -0.477468   -0.178319  \n3   -2.818301   -0.395545   -0.738405    0.369630  \n4   -3.665342   -0.922017   -0.364447   -0.055827  \n\n[5 rows x 1761 columns]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = pd.read_csv('Datos/val/DatosValidacion1.csv')\n",
    "# Creamos una columna enumerando cada fila\n",
    "val_data = val_data.assign(num=[1500 + i for i in range(len(val_data))])[['num'] + val_data.columns.tolist()]\n",
    "val_data.pop(\"sequence\")\n",
    "y2 = val_data.pop(\"class\")\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num</th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>length</th>\n      <th>molecular_weight</th>\n      <th>charge</th>\n      <th>charge_density</th>\n      <th>isoelectric_point</th>\n      <th>gravy</th>\n      <th>instability_index</th>\n      <th>...</th>\n      <th>embed_2_90</th>\n      <th>embed_2_91</th>\n      <th>embed_2_92</th>\n      <th>embed_2_93</th>\n      <th>embed_2_94</th>\n      <th>embed_2_95</th>\n      <th>embed_2_96</th>\n      <th>embed_2_97</th>\n      <th>embed_2_98</th>\n      <th>embed_2_99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>-1.730984</td>\n      <td>-1.704958</td>\n      <td>-1.710290</td>\n      <td>1.200441</td>\n      <td>1.488957</td>\n      <td>2.993163</td>\n      <td>2.041380</td>\n      <td>1.680420</td>\n      <td>0.057637</td>\n      <td>1.795329</td>\n      <td>...</td>\n      <td>-0.709365</td>\n      <td>1.945619</td>\n      <td>-1.703364</td>\n      <td>0.675871</td>\n      <td>1.054814</td>\n      <td>3.373537</td>\n      <td>-2.357323</td>\n      <td>0.456880</td>\n      <td>-0.985170</td>\n      <td>-1.610517</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>-1.728850</td>\n      <td>-1.703898</td>\n      <td>-1.709234</td>\n      <td>1.346667</td>\n      <td>1.627166</td>\n      <td>2.600490</td>\n      <td>1.720552</td>\n      <td>1.201197</td>\n      <td>-0.688985</td>\n      <td>1.474132</td>\n      <td>...</td>\n      <td>-0.996886</td>\n      <td>1.241833</td>\n      <td>-0.840013</td>\n      <td>0.748034</td>\n      <td>-0.608378</td>\n      <td>2.709067</td>\n      <td>-2.344236</td>\n      <td>-0.497817</td>\n      <td>-2.046474</td>\n      <td>-0.469698</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>-1.726715</td>\n      <td>-1.702838</td>\n      <td>-1.708178</td>\n      <td>1.492893</td>\n      <td>1.781575</td>\n      <td>2.279148</td>\n      <td>1.458301</td>\n      <td>0.969138</td>\n      <td>-0.565795</td>\n      <td>-0.703036</td>\n      <td>...</td>\n      <td>-0.478661</td>\n      <td>1.930022</td>\n      <td>-2.796106</td>\n      <td>-0.537628</td>\n      <td>0.728976</td>\n      <td>3.854966</td>\n      <td>-3.264137</td>\n      <td>-0.286104</td>\n      <td>-0.176447</td>\n      <td>-1.318507</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>-1.724581</td>\n      <td>-1.701777</td>\n      <td>-1.707123</td>\n      <td>0.907989</td>\n      <td>1.411661</td>\n      <td>2.243483</td>\n      <td>1.548356</td>\n      <td>1.045248</td>\n      <td>-0.067074</td>\n      <td>0.662700</td>\n      <td>...</td>\n      <td>-0.801345</td>\n      <td>0.198585</td>\n      <td>-2.132271</td>\n      <td>1.653474</td>\n      <td>0.157642</td>\n      <td>1.263816</td>\n      <td>-1.014032</td>\n      <td>0.841203</td>\n      <td>-0.977964</td>\n      <td>0.698452</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>-1.722446</td>\n      <td>-1.700717</td>\n      <td>-1.706067</td>\n      <td>1.200441</td>\n      <td>1.250947</td>\n      <td>1.174245</td>\n      <td>0.827828</td>\n      <td>0.719407</td>\n      <td>1.154235</td>\n      <td>0.959383</td>\n      <td>...</td>\n      <td>-1.009921</td>\n      <td>0.185188</td>\n      <td>-1.631771</td>\n      <td>0.874250</td>\n      <td>0.831410</td>\n      <td>1.551430</td>\n      <td>-2.118977</td>\n      <td>-0.676961</td>\n      <td>0.170717</td>\n      <td>-0.867622</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1761 columns</p>\n</div>",
      "text/plain": "        num  Unnamed: 0  Unnamed: 0.1    length  molecular_weight    charge  \\\n0 -1.730984   -1.704958     -1.710290  1.200441          1.488957  2.993163   \n1 -1.728850   -1.703898     -1.709234  1.346667          1.627166  2.600490   \n2 -1.726715   -1.702838     -1.708178  1.492893          1.781575  2.279148   \n3 -1.724581   -1.701777     -1.707123  0.907989          1.411661  2.243483   \n4 -1.722446   -1.700717     -1.706067  1.200441          1.250947  1.174245   \n\n   charge_density  isoelectric_point     gravy  instability_index  ...  \\\n0        2.041380           1.680420  0.057637           1.795329  ...   \n1        1.720552           1.201197 -0.688985           1.474132  ...   \n2        1.458301           0.969138 -0.565795          -0.703036  ...   \n3        1.548356           1.045248 -0.067074           0.662700  ...   \n4        0.827828           0.719407  1.154235           0.959383  ...   \n\n   embed_2_90  embed_2_91  embed_2_92  embed_2_93  embed_2_94  embed_2_95  \\\n0   -0.709365    1.945619   -1.703364    0.675871    1.054814    3.373537   \n1   -0.996886    1.241833   -0.840013    0.748034   -0.608378    2.709067   \n2   -0.478661    1.930022   -2.796106   -0.537628    0.728976    3.854966   \n3   -0.801345    0.198585   -2.132271    1.653474    0.157642    1.263816   \n4   -1.009921    0.185188   -1.631771    0.874250    0.831410    1.551430   \n\n   embed_2_96  embed_2_97  embed_2_98  embed_2_99  \n0   -2.357323    0.456880   -0.985170   -1.610517  \n1   -2.344236   -0.497817   -2.046474   -0.469698  \n2   -3.264137   -0.286104   -0.176447   -1.318507  \n3   -1.014032    0.841203   -0.977964    0.698452  \n4   -2.118977   -0.676961    0.170717   -0.867622  \n\n[5 rows x 1761 columns]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizamos el set de datos de validación\n",
    "names = val_data.columns\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_val_data = scaler.fit_transform(val_data)\n",
    "scaled_val_data  = pd.DataFrame(scaled_val_data, columns=names)\n",
    "scaled_val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_x = scaled_val_data[priorizadas]\n",
    "data_val_y = y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n                       warm_start=False)"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Validación\n",
    "# Entrenamos un modelo con Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(bal_data_X[priorizadas], bal_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1099,   13],\n       [   8, 1657]], dtype=int64)"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacemos predicciones con la data de prueba\n",
    "predict = rf.predict(X_test[priorizadas])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      1112\n           1       0.99      1.00      0.99      1665\n\n    accuracy                           0.99      2777\n   macro avg       0.99      0.99      0.99      2777\nweighted avg       0.99      0.99      0.99      2777\n\n"
    }
   ],
   "source": [
    "# Revisamos otras metricas del modelo\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [10, 20, 30, 50, 100, 200, 500, 1000, 2000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [1,2,3,4,5,6,7,8,9,10],\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "    'min_samples_leaf': [3, 4, 5, 7, 10, 15, 20, 30, 50],  \n",
    "    #'params': [{'kernel' : 'rbf', 'gamma' : 0.1}, ...],  \n",
    "    'min_samples_split': [8, 10, 12, 16, 20, 30, 50, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=3, error_score=nan,\n                   estimator=RandomForestClassifier(bootstrap=True,\n                                                    ccp_alpha=0.0,\n                                                    class_weight=None,\n                                                    criterion='gini',\n                                                    max_depth=None,\n                                                    max_features='auto',\n                                                    max_leaf_nodes=None,\n                                                    max_samples=None,\n                                                    min_impurity_decrease=0.0,\n                                                    min_impurity_split=None,\n                                                    min_samples_leaf=1,\n                                                    min_samples_split=2,\n                                                    min_weight_fraction_leaf=0.0,\n                                                    n_estimators=100,\n                                                    n_jobs...\n                   param_distributions={'criterion': ['gini', 'entropy'],\n                                        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n                                                      10],\n                                        'max_features': ['auto', 'sqrt',\n                                                         'log2'],\n                                        'min_samples_leaf': [3, 4, 5, 7, 10, 15,\n                                                             20, 30, 50],\n                                        'min_samples_split': [8, 10, 12, 16, 20,\n                                                              30, 50, 100,\n                                                              200],\n                                        'n_estimators': [10, 20, 30, 50, 100,\n                                                         200, 500, 1000,\n                                                         2000]},\n                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n                   return_train_score=False, scoring=None, verbose=0)"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_rdm= RandomizedSearchCV(estimator=rf, param_distributions=param_grid, cv= 3, n_iter=100, n_jobs=-1)\n",
    "rf_rdm.fit(bal_data_X[priorizadas], bal_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_estimators': 1000,\n 'min_samples_split': 12,\n 'min_samples_leaf': 5,\n 'max_features': 'auto',\n 'max_depth': 9,\n 'criterion': 'entropy'}"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rdm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 1000, max_depth=9, criterion='entropy', min_samples_split = 12,min_samples_leaf = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 345, 1009],\n       [  24,  245]], dtype=int64)"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.fit(bal_data_X[priorizadas], bal_data_y)\n",
    "predict1 = rf1.predict(data_val_x[priorizadas])\n",
    "confusion_matrix(data_val_y, predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "precision    recall  f1-score   support\n\n           0       0.93      0.25      0.40      1354\n           1       0.20      0.91      0.32       269\n\n    accuracy                           0.36      1623\n   macro avg       0.57      0.58      0.36      1623\nweighted avg       0.81      0.36      0.39      1623\n\n"
    }
   ],
   "source": [
    "print(classification_report(data_val_y, predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[186  45]\n [ 24 245]]\n              precision    recall  f1-score   support\n\n           0       0.89      0.81      0.84       231\n           1       0.84      0.91      0.88       269\n\n    accuracy                           0.86       500\n   macro avg       0.87      0.86      0.86       500\nweighted avg       0.86      0.86      0.86       500\n\n"
    }
   ],
   "source": [
    "predict1 = rf1.predict(data_val_x[0:500])\n",
    "print(confusion_matrix(data_val_y[0:500], predict1))\n",
    "print(classification_report(data_val_y[0:500], predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[127 372]\n [  0   0]]\n              precision    recall  f1-score   support\n\n           0       1.00      0.25      0.41       499\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.25       499\n   macro avg       0.50      0.13      0.20       499\nweighted avg       1.00      0.25      0.41       499\n\n"
    }
   ],
   "source": [
    "predict1 = rf1.predict(data_val_x[501:1000])\n",
    "print(confusion_matrix(data_val_y[501:1000], predict1))\n",
    "print(classification_report(data_val_y[501:1000], predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 31 591]\n [  0   0]]\n              precision    recall  f1-score   support\n\n           0       1.00      0.05      0.09       622\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.05       622\n   macro avg       0.50      0.02      0.05       622\nweighted avg       1.00      0.05      0.09       622\n\n"
    }
   ],
   "source": [
    "predict1 = rf1.predict(data_val_x[1001:1623])\n",
    "print(confusion_matrix(data_val_y[1001:1623], predict1))\n",
    "print(classification_report(data_val_y[1001:1623], predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Iteración: 0 , 0 - 100\nAccuracy: 0.94\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         0\n           1       1.00      0.94      0.97       100\n\n    accuracy                           0.94       100\n   macro avg       0.50      0.47      0.48       100\nweighted avg       1.00      0.94      0.97       100\n\nIteración: 1 , 100 - 200\nAccuracy: 0.93\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         0\n           1       1.00      0.93      0.96       100\n\n    accuracy                           0.93       100\n   macro avg       0.50      0.47      0.48       100\nweighted avg       1.00      0.93      0.96       100\n\nIteración: 2 , 200 - 300\nAccuracy: 0.85\n              precision    recall  f1-score   support\n\n           0       0.71      0.87      0.78        31\n           1       0.94      0.84      0.89        69\n\n    accuracy                           0.85       100\n   macro avg       0.82      0.86      0.83       100\nweighted avg       0.87      0.85      0.85       100\n\nIteración: 3 , 300 - 400\nAccuracy: 0.85\n              precision    recall  f1-score   support\n\n           0       1.00      0.85      0.92       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.85       100\n   macro avg       0.50      0.42      0.46       100\nweighted avg       1.00      0.85      0.92       100\n\nIteración: 4 , 400 - 500\nAccuracy: 0.74\n              precision    recall  f1-score   support\n\n           0       1.00      0.74      0.85       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.74       100\n   macro avg       0.50      0.37      0.43       100\nweighted avg       1.00      0.74      0.85       100\n\nIteración: 5 , 500 - 600\nAccuracy: 0.77\n              precision    recall  f1-score   support\n\n           0       1.00      0.77      0.87       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.77       100\n   macro avg       0.50      0.39      0.44       100\nweighted avg       1.00      0.77      0.87       100\n\nIteración: 6 , 600 - 700\nAccuracy: 0.34\n              precision    recall  f1-score   support\n\n           0       1.00      0.34      0.51       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.34       100\n   macro avg       0.50      0.17      0.25       100\nweighted avg       1.00      0.34      0.51       100\n\nIteración: 7 , 700 - 800\nAccuracy: 0.06\n              precision    recall  f1-score   support\n\n           0       1.00      0.06      0.11       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.06       100\n   macro avg       0.50      0.03      0.06       100\nweighted avg       1.00      0.06      0.11       100\n\nIteración: 8 , 800 - 900\nAccuracy: 0.03\n              precision    recall  f1-score   support\n\n           0       1.00      0.03      0.06       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.03       100\n   macro avg       0.50      0.01      0.03       100\nweighted avg       1.00      0.03      0.06       100\n\nIteración: 9 , 900 - 1000\nAccuracy: 0.08\n              precision    recall  f1-score   support\n\n           0       1.00      0.08      0.15       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.08       100\n   macro avg       0.50      0.04      0.07       100\nweighted avg       1.00      0.08      0.15       100\n\nIteración: 10 , 1000 - 1100\nAccuracy: 0.02\n              precision    recall  f1-score   support\n\n           0       1.00      0.02      0.04       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.02       100\n   macro avg       0.50      0.01      0.02       100\nweighted avg       1.00      0.02      0.04       100\n\nIteración: 11 , 1100 - 1200\nAccuracy: 0.04\n              precision    recall  f1-score   support\n\n           0       1.00      0.04      0.08       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.04       100\n   macro avg       0.50      0.02      0.04       100\nweighted avg       1.00      0.04      0.08       100\n\nIteración: 12 , 1200 - 1300\nAccuracy: 0.08\n              precision    recall  f1-score   support\n\n           0       1.00      0.08      0.15       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.08       100\n   macro avg       0.50      0.04      0.07       100\nweighted avg       1.00      0.08      0.15       100\n\nIteración: 13 , 1300 - 1400\nAccuracy: 0.04\n              precision    recall  f1-score   support\n\n           0       1.00      0.04      0.08       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.04       100\n   macro avg       0.50      0.02      0.04       100\nweighted avg       1.00      0.04      0.08       100\n\nIteración: 14 , 1400 - 1500\nAccuracy: 0.02\n              precision    recall  f1-score   support\n\n           0       1.00      0.02      0.04       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.02       100\n   macro avg       0.50      0.01      0.02       100\nweighted avg       1.00      0.02      0.04       100\n\nIteración: 15 , 1500 - 1600\nAccuracy: 0.09\n              precision    recall  f1-score   support\n\n           0       1.00      0.09      0.17       100\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.09       100\n   macro avg       0.50      0.04      0.08       100\nweighted avg       1.00      0.09      0.17       100\n\nIteración: 16 , 1600 - 1700\nAccuracy: 0.08695652173913043\n              precision    recall  f1-score   support\n\n           0       1.00      0.09      0.16        23\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.09        23\n   macro avg       0.50      0.04      0.08        23\nweighted avg       1.00      0.09      0.16        23\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ini = -1\n",
    "fin = 100\n",
    "for i in range(17):\n",
    "    ini = ini + 1\n",
    "    print(\"Iteración:\", i, \",\", ini, \"-\", fin )\n",
    "    predict1 = rf1.predict(data_val_x[ini:fin])\n",
    "    print(\"Accuracy:\", accuracy_score(data_val_y[ini:fin],predict1) )\n",
    "    print(classification_report(data_val_y[ini:fin], predict1))\n",
    "    ini += 99\n",
    "    fin += 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}